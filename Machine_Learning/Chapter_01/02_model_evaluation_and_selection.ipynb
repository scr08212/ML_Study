{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae57f65",
   "metadata": {},
   "source": [
    "##### **목차**\n",
    "<details>\n",
    "<summary>CHAPTER 02 모델 평가 및 선택 29</summary>\n",
    "2.1 경험 오차 및 과적합 29<br>\n",
    "2.2 평가 방법 31<br>\n",
    "2.3 모델 성능 측정 37<br>\n",
    "2.4 비교 검증 47<br>\n",
    "2.5 편향과 분산 57<br>\n",
    "2.6 더 읽을거리 59<br>\n",
    "연습문제 61<br>\n",
    "참고문헌 62<br>\n",
    "머신러닝 쉼터 64<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37af8c",
   "metadata": {},
   "source": [
    "### **2.1 경험 오차 및 과적합**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97cd400",
   "metadata": {},
   "source": [
    "##### 용어\n",
    "\n",
    "| 용어(한글)            | 영문/표기                  | 정의                                                         | 예시                                    | 비고/주의                                    |\n",
    "|----------------------|----------------------------|--------------------------------------------------------------|-----------------------------------------|----------------------------------------------|\n",
    "| 오차율           | error rate                   | 전체 샘플수와 잘못 분류한 샘플 수의 비율                             | m개의 샘플중 e개의 샘플이 잘못 분류되었을 경우 -> E = a/m                      |                  |\n",
    "| 정밀도           | accuracy                   | 전체 샘플수와 제대로 분류한  샘플 수의 비율                             | 1 - a/m = 1 - 오차율                      |                  |\n",
    "| 오차           | error                   | 학습기의 실제 예측 값과  샘플의 실제 값 사이의 차이                             |                       |                  |\n",
    "| 훈련 오차           | training error                   | 학습기가 훈련세트 상에서 만들어낸 오차                             |                       |                  |\n",
    "| 일반화 오차           | generalization error                   | 학습기가 새로운 샘플 위에서 만들어낸 오차                             |                       |                  |\n",
    "| 과적합           | overfitting                   | 학습기가 훈련 데이터에서 학습을 과도하게 잘하여 일반화 성능이 떨어짐                            |                       | 극복하기 어려움                 |\n",
    "| 과소적합           | underfitting                   | 학습기가 훈련 데이터의 일반 성질을 제대로 배우지 못함                             |                       | 극복하기 쉬움                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f32c1b",
   "metadata": {},
   "source": [
    "같은 학습 알고리즘이라 하더라도, 파라미터에 따라 다른 모델로 불리기도 한다. 이때 어떤 모델을 선택해야 할까?  \n",
    "일반화 오차가 가장 작은 모델을 선택하는게 이상적이지만, 우리는 일반화 오차를 직접적으로 얻을 수 없다.  \n",
    "또한, 훈련 오차가 가장 작은 모델을 선택하게 된다면, 과적합의 우려가 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffaf37",
   "metadata": {},
   "source": [
    "### **2.2 평가 방법**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaa6b0",
   "metadata": {},
   "source": [
    "우리에게 m개의 샘플을 가진 데이터 세트 D = {(x1, y1), (x2, y2), ..., (xm, ym)}가 있다고 하자.  \n",
    "이때 어떻게 훈련과 평가를 수행할 수 있을까?  \n",
    "일반적으로 데이터 세트 D를 적절히 분할하여 훈련 세트 S와 테스트 세트 T로 나누어 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69179fb0",
   "metadata": {},
   "source": [
    "#### 2.2.1 홀드아웃(Hold-out)\n",
    "\n",
    "1. 데이터 세트 D를 임의의 두 부분 집합, 즉 훈련 세트 S와 테스트 세트 T로 나눈다.  \n",
    "   (가능하면 데이터 분포를 유지하도록 나누는 것이 바람직하다.)\n",
    "2. 훈련 세트 S로 학습한 모델의 성능을 테스트 세트 T로 측정하여 일반화 오차에 대한 추정치를 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4d376",
   "metadata": {},
   "source": [
    "##### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74fb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from collections import Counter\n",
    "\n",
    "data = load_iris()\n",
    "x = data.data\n",
    "y = data.target\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(x))\n",
    "np.random.shuffle(indices)\n",
    "x, y = x[indices],  y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37df74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out(split_ratio = 0.7):\n",
    "    split_idx = int(len(x) * split_ratio)\n",
    "    x_train, x_test = x[:split_idx], x[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be0235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hold-out] Accuracy: 0.2222\n"
     ]
    }
   ],
   "source": [
    "# 간단한 검증\n",
    "x_train, x_test, y_train, y_test = hold_out(split_ratio=0.7)\n",
    "majority_class = Counter(y_train).most_common(1)[0][0] # 최빈 클래스 추출\n",
    "y_pred = np.full(len(y_test), majority_class) # 모든 테스트 샘플을 최빈 클래스로 예측\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"[Hold-out] Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6601b44",
   "metadata": {},
   "source": [
    "#### 2.2.2 교차 검증(Cross-validation)\n",
    "\n",
    "1. 데이터 세트 D를 k개의 서로소 부분 집합으로 나눈다.  \n",
    "   (역시 데이터 분포를 유지하도록 나누는 것이 바람직하다.)\n",
    "2. 각 반복에서 k-1개의 부분집합을 훈련 세트로 사용하고, 나머지 1개의 부분집합을 테스트 세트로 사용한다.\n",
    "3. 이렇게 k개의 훈련/테스트 세트를 만들어 k번 훈련과 테스트를 수행한 뒤, k개의 테스트 결과의 평균을 계산해 모델 성능을 평가한다.\n",
    "\n",
    "교차 검증 결과의 안정성과 정확도는 k의 값에 따라 달라진다.  \n",
    "이를 k겹 교차 검증(k-fold cross-validation)이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f1cf2",
   "metadata": {},
   "source": [
    "##### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65bd7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k = 5):\n",
    "    fold_size = len(x) // k\n",
    "    accuracies = [] \n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < k else len(x)\n",
    "\n",
    "        x_test = x[start:end]\n",
    "        y_test = y[start:end]\n",
    "\n",
    "        x_train = np.concatenate([x[:start], x[end:]], axis = 0)\n",
    "        y_train = np.concatenate([y[:start], y[end:]], axis = 0)\n",
    "\n",
    "        majority_class = Counter(y_train).most_common(1)[0][0] # 최빈 클래스 추출\n",
    "        y_pred = np.full(len(y_test), majority_class) # 모든 테스트 샘플을 최빈 클래스로 예측\n",
    "        accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "    print(f\"[Cross-validation] Accuracies: {accuracies}\")\n",
    "    print(f\"[Cross-validation] Mean accuracy: {np.mean(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f3ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cross-validation] Accuracies: [np.float64(0.3), np.float64(0.23333333333333334), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.23333333333333334)]\n",
      "[Cross-validation] Mean accuracy: 0.2600\n"
     ]
    }
   ],
   "source": [
    "cross_validation(k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431dde0",
   "metadata": {},
   "source": [
    "#### 2.2.3 부트스트래핑(Bootstrapping)\n",
    "\n",
    "홀드아웃이나 교차 검증 방식은 일부 샘플을 테스트용으로 제외하므로 훈련에 모든 샘플을 활용할 수 없다는 단점이 있다.  \n",
    "만약 데이터 세트 D의 모든 샘플을 훈련에 사용하고 싶다면, 부트스트래핑 기법이 유용하다.\n",
    "\n",
    "1. 데이터 세트 D에는 m개의 샘플이 있다. 새로운 데이터 세트 D'를 비워둔 상태로 시작한다.\n",
    "2. D에서 무작위로 샘플 하나를 선택하여 D'에 복사한다. 이때 같은 샘플이 중복해서 선택될 수 있다.\n",
    "3. 이 과정을 m번 반복하면, D'에는 m개의 샘플이 들어가게 된다.\n",
    "4. 수학적으로, m번 복원추출을 할 때 샘플이 한 번도 뽑히지 않을 확률은  \n",
    "   (1 - 1/m)^m ≈ e^-1 ≈ 36.8%이다.  \n",
    "   즉, 데이터 세트 D의 약 36.8%의 샘플은 D'에 포함되지 않는다.\n",
    "5. 이렇게 만들어진 D'를 훈련 세트로 사용하고, D에서 선택되지 않은 샘플들을 테스트 세트로 사용한다.\n",
    "\n",
    "부트스트래핑의 특징:\n",
    "- 데이터 양이 적거나, 훈련/테스트 분할이 어려울 때 유용하다.\n",
    "- 앙상블 학습 기법(예: 배깅)과 잘 어울린다.\n",
    "- 단점으로, D'의 데이터 분포가 원본 D와 다를 수 있어 편향이 발생할 수 있다.\n",
    "- 따라서 데이터가 풍부하다면 홀드아웃이나 교차 검증을 더 자주 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba4b87",
   "metadata": {},
   "source": [
    "##### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fefbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping():\n",
    "    m = len(x)\n",
    "    bootstrap_indices = np.random.choice(np.arange(m), size = m, replace=True)\n",
    "    oob_indices = np.setdiff1d(np.arange(m), np.unique(bootstrap_indices))\n",
    "\n",
    "    x_train = x[bootstrap_indices]\n",
    "    x_test = x[oob_indices]\n",
    "    y_train = y[bootstrap_indices]\n",
    "    y_test = y[oob_indices]\n",
    "    \n",
    "    majority_class = Counter(y_train).most_common(1)[0][0] # 최빈 클래스 추출\n",
    "    y_pred = np.full(len(y_test), majority_class) # 모든 테스트 샘플을 최빈 클래스로 예측\n",
    "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "    print(f\"[Bootstrap] 선택되지 않은 샘플 비율 : {(len(oob_indices) / m):.4f}\")\n",
    "    # 정확도\n",
    "    if len(y_test) > 0:\n",
    "        accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "        print(f\"[Bootstrap] Accuracy: {accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"[Bootstrap] OOB 샘플이 없어 정확도를 계산할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf45beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bootstrap] 선택되지 않은 샘플 비율 : 0.4000\n",
      "[Bootstrap] Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "bootstrapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce676d4",
   "metadata": {},
   "source": [
    "#### **2.3 모델 성능 측정**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2619a3",
   "metadata": {},
   "source": [
    "#### **2.4 비교 검증**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d7c7f",
   "metadata": {},
   "source": [
    "#### **2.5 편향과 분산**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
