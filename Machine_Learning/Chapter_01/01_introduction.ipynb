{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76465a7c",
   "metadata": {},
   "source": [
    "#### **1. 머신러닝이란?**  \n",
    "  머신러닝이란, 명시적으로 프로그래밍하지 않아도 컴퓨터가 데이터로부터 스스로 학습하고 성능을 개선할 수 있도록 하는 기술이다.\n",
    "  > &nbsp;**Tom M. Mitchell (1997)**  \n",
    "  > &nbsp;&nbsp;&nbsp;어떤 작업 T와 성능 측정 P, 경험 E가 있을 때,  \n",
    "  > &nbsp;&nbsp;&nbsp;컴퓨터 프로그램이 경험 E를 통해 작업 T에서 성능 측정치 P를 향상시키는 경우,  \n",
    "  > &nbsp;&nbsp;&nbsp;그 프로그램이 학습한다고 한다.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252f8fb",
   "metadata": {},
   "source": [
    "#### **2. 머신러닝의 기본 용어**  \n",
    "\n",
    "| 용어(한글)            | 영문/표기                  | 정의                                                         | 예시                                    | 비고/주의                                    |\n",
    "|----------------------|----------------------------|--------------------------------------------------------------|-----------------------------------------|----------------------------------------------|\n",
    "| 데이터 세트           | data set                   | 전체 데이터의 모임. 샘플들의 집합                             | MNIST 전체 데이터                      | 데이터셋, dataset이라고도 함                 |\n",
    "| 샘플, 인스턴스        | sample, instance           | 데이터 세트 안의 개별 데이터                                  | 한 학생의 정보                         | 두 용어 거의 동의어                         |\n",
    "| 샘플 공간             | sample space               | 모든 가능한 샘플의 집합                                       | 모든 학생 정보 조합                    |                                            |\n",
    "| 특성, 속성           | feature, attribute         | 사물이나 대상의 성질을 반영하는 것                                        | 키, 몸무게, 성별                        | feature를 주로 사용                         |\n",
    "| 속성값                | attribute value            | 속성이 취할 수 있는 값                                 | 키: 172cm                              |                                            |\n",
    "| 속성 공간             | attribute space            | 모든 속성의 가능한 값들의 공간                                | (키, 몸무게) 2차원 공간                | 특성 공간이라고도 함                        |\n",
    "| 특성 벡터             | feature vector             | 한 샘플의 모든 특성값을 벡터로 표현한 것                      | [172, 68, 1]                           | 입력 벡터, x로 자주 사용                    |\n",
    "| 차원수                | dimensionality             | 데이터가 가진 특성(변수)의 수                                 | 3차원(키, 몸무게, 나이)                | 고차원 데이터일수록 차원의 저주 발생         |\n",
    "| 레이블                | label                      | 샘플에 할당된 정답 값                                         | 정상/비정상, 고양이/개                  | ground truth와 유사                         |\n",
    "| 레이블 공간           | label space                | 예측 가능한 정답값(레이블)의 집합                                | {0,1}, {A,B,C}                         | 회귀는 연속값(실수) 집합                    |\n",
    "| 학습, 훈련            | learning, training         | 데이터를 통해 모델 파라미터를 조정하는 과정                    | 선형회귀 모델의 학습                   |                                            |\n",
    "| 훈련 데이터           | training data              | 학습에 사용되는 데이터 집합                                   | MNIST 훈련 데이터                      |                                            |\n",
    "| 훈련 세트             | training set            | 훈련 샘플의 집합                             | 손글씨 숫자 여러 장                      |                                            |\n",
    "| 훈련 샘플             | training sample            | 훈련 데이터에 속하는 각 개별 샘플                             | 손글씨 숫자 한 장                      |                                            |\n",
    "| 가설                  | hypothesis                 | 데이터 속에 잠재된 어떠한 규칙                 | y = w*x + b, 트리 모델                 | 가설 공간 내에서 최적 가설 찾기             |\n",
    "| 진실                  | ground truth               | 데이터의 실제 정답                                            | 스팸 여부, 실제 질병 유무               | 레이블, 정답(label)과 유사                  |\n",
    "| 분류                  | classification             | 입력 데이터를 클래스 중 하나로 분류                            | 숫자 인식, 이메일 스팸 분류             | 지도학습의 대표적 문제                     |\n",
    "| 회귀                  | regression                 | 연속적인 수치값을 예측하는 문제                               | 집값 예측                              | 지도학습                                    |\n",
    "| 군집화                | clustering                 | 레이블 없이 비슷한 샘플을 자동으로 묶는 과정                     | 고객 세분화                            | 비지도학습의 대표적 방법                    |\n",
    "| 군집                  | cluster                    | 군집화 결과로 만들어진 그룹                                   | 20대 그룹, 30대 그룹                    |                                            |\n",
    "| 지도학습              | supervised learning        | 정답(레이블)이 있는 데이터로 모델을 학습하는 방법                | 이미지 분류                            | 분류, 회귀 모두 포함                        |\n",
    "| 비지도학습            | unsupervised learning      | 정답 없이 데이터 구조를 찾는 학습                             | 군집화, 차원 축소                       |                                            |\n",
    "| 예측                  | prediction                 | 모델이 새 데이터에 대해 내놓는 결과                            | “이 이메일은 스팸”                      | 실제 정답과 다를 수 있음                    |\n",
    "| 검증                  | testing                    | 학습된 모델의 성능을 새 데이터로 평가하는 과정                 | 테스트셋으로 평가                       | 평가(evaluation)와 혼용됨                   |\n",
    "| 테스트 샘플           | testing sample             | 검증(테스트)에 쓰는 데이터 한 줄                              | 테스트용 손글씨 이미지 한 장            |                                            |\n",
    "| 일반화                | generalization             | 학습에 쓰이지 않은 새로운 데이터에서도 잘 맞추는 능력           | 새 시험 문제도 잘 푸는 것               | 과적합의 반대 개념                          |\n",
    "| 독립항등분포           | independent and identically distributed, i.i.d                      | 각 샘플이 서로 독립적이고, 같은 분포에서 추출된다는 가정        | 동전 던지기 여러 번                     | 대부분의 ML 이론이 이 가정 위에 있음        |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055f92e",
   "metadata": {},
   "source": [
    "#### **3. 가설 공간(hypothesis space)** \n",
    " 가설 공간이란 가설의 집합으로, 학습 알고리즘이 선택할 수 있는 모든 함수의 집합을 의미한다.  \n",
    " 따라서, 학습은 해당 가설 공간 내에서 훈련 데이터와 가장 잘 맞는(fit) 가설을 찾는 것이다.\n",
    "\n",
    " 주의할 점은 현실에서는 자주 매우 큰 가설 공간을 만나게 된다. 하지만 학습은 한정적인 데이터로만 진행된다. \n",
    " 따라서 많은 가설이 훈련 데이터셋과 일치할 수 있고, 훈련 데이터셋과 일치하는 '가설들의 집합'이 존재하게 된다. 이를 `버전 공간` 이라 부른다.  \n",
    " 버전 공간 안에는 동일하게 훈련 데이터를 설명하는 많은 가설이 존재할 수 있다. 어떤 가설을 최종적으로 선택할지는 학습 알고리즘의 `귀납적 편향`에 의해 결정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a945e7c",
   "metadata": {},
   "source": [
    "#### **4. 귀납적 편향(Inductive bias)** \n",
    " 귀납적 편향 또는 편향(bias)은 머신러닝 알고리즘 학습 과정에서 특정한 유형의 가설에 대한 편향을 의미한다.  \n",
    " 하지만, 만약 편향이 너무 강할 경우 언더피팅이 생길 수 있으며, 너무 약할 경우 오버피팅이 발생할 수 있다.  \n",
    " 따라서, 편향-분산 트레이드오프와 밀접한 관련이 있다.\n",
    "\n",
    " **예시:** 선형 모델의 귀납적 편향:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;“세상은 선형적으로 설명될 수 있다”는 가정(=비선형적인 관계는 아예 고려하지 않음)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
